---
layout: vanilla
permalink: /docs/
description: "Tutorials for Mouse Atlas."
modified: 2018-01-13
tags: [mouse, manual, vignette, atlas]
---
<!DOCTYPE html>
<html lang= "{{ page.lang | default: site.lang | default: "en" }}">

  {% include head.html %}

  <!-- See here for how to use the TOC control:
  https://afeld.github.io/bootstrap-toc/ -->
  <body  data-spy= "scroll" data-target= "#toc">
    {% include header.html %}

    <div class= "container">
      <div class= "row">
        <!-- sidebar, which will move to the top on a small screen -->
        <div class= "col-sm-4 sidenav">
          <nav id= "toc" data-spy= "affix" data-toggle= "toc"></nav>
        </div>
        <!-- main content area -->
        <div class= "col-sm-8">
    <h2>Generating Peak by Cell Matrices</h2>
    <p>Many of the initial steps of our sci-ATAC-seq processing are the same or similar to other published documentation. Documentation on preprocessing of sci-ATAC-seq data can be found on <a href="https://github.com/shendurelab/fly-atac">Github</a>. Documentation on establishing initial clades of cells using windows across the genome (as generated using the approach on Github) can be found on the <a href="http://atlas.gs.washington.edu/fly-atac/docs/#use-case-1-id-clades-with-lsi">Fly ATAC webpage</a>.</p>

    <p>The above documentation should allow you to obtain a binarized matrix of peaks by cells for a given dataset. Alternatively, you can download the datasets we provide <a href='/data/'>on our downloads page</a> as a starting point.</p>

    <p>Below we document features that are new or different in the mouse atlas data processing and analysis.</p>

    <h2>Loading Matrix Files</h2>
    <p>Through our <a href='/data/'>downloads page</a> we provide two major formats for all matrix data, matrix-market and RDS.</p>
    <h3>Matrix Market Format</h3>
    <p>Matrix market format is the format used by the <code>cellranger</code> pipeline from 10X genomics, which may be familiar to many of you. This format is simply a text file that allows reconstruction of a sparse matrix, along with the peak (or gene) and cell names that specify the row and column names of the matrix, respectively.</p>

    <p>This format is readable in <code>R</code>:
    <figure class="highlight">
    <pre><code class="language-r" data-lang="r">library(Matrix)
my_matrix = readMM("my_matrix.mtx.gz")
row.names(my_matrix) = read.delim('my_matrix.peaks.txt', header=FALSE)$V1
colnames(my_matrix) = read.delim('my_matrix.cells.txt', header=FALSE)$V1</code></pre>
    </figure>

<div class="spacer"></div>

    <p>as well as <code>python</code> (based on code from <a href="https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices">10X Genomics Documentation</a>). Note the code below requires <code>scipy</code> to be installed in your python environment:</p>

    <figure class="highlight">
    <pre><code class="language-python" data-lang="python">import csv
import scipy.io

mat = scipy.io.mmread("my_matrix.mtx.gz")
peaks = [row[0] for row in csv.reader(open("my_matrix.peaks.txt"), delimiter="\t")]
cells = [row[0] for row in csv.reader(open("my_matrix.cells.txt"), delimiter="\t")]</code></pre>
    </figure>

<div class="spacer"></div>

<p>In principle this text format is readable in many other languages as well, although all of our tutorials are written in <code>R</code>.</p>

    <h3>RDS Format</h3>
    <p>We also provide these matrices in RDS format, which is easily readable in <code>R</code>, but has less cross-compatability with other languages. Row and column names are already associated with the matrix.</code></p>

    <figure class="highlight">
    <pre><code class="language-r" data-lang="r">library(Matrix)
my_matrix = readRDS("my_matrix.rds")</code></pre>
    </figure>

    <h2>Nucleosome Banding Scores</h2>
    <p>One of the new quality control steps that we have used in this manuscript is scoring of invidual cells for evidence of a banded insert size distribution that would be indicative of a high-quality ATAC-seq library. We do this by first extracting an insert size distribution for each cell and then calculating a score using an FFT of this distribution.</p>

         <div class= "panel panel-warning">
            <div class= "panel-heading">
            <h3 class= "panel-title" data-toc-skip>Performance</h3>
            </div>
            <div class= "panel-body">
        <p>The current implementation of the scripts below is a proof of concept and could use further performance optimization to reduce runtimes.

        <p>As such, we recommend using a whitelist of cell barcodes to limit computations to non-background cells (cells that meet your reads per cell threshold and other quality control steps). This file, a text file with one cell barcode per line, can be provided with the <code>--barcodes</code> argument in both scripts below.</p>

        <p>The main bottleneck currently seems to be the FFT step, which should be readily optimizable using alternative implementations in R or python.</p>

            </div>
          </div>

    <h3>Extracting Insert-Size Distributions</h3>
    <p>The first step is to extract a histogram of insert sizes across all reads associated with each cell. The input to this script is a BAM file of the aligned reads and the output is a per-cell histogram of insert sizes in TSV format.</p>

    <p>It assumes that the read names come in the format <code>cellid:other_text</code>, which allows the cell ID to be extracted. The script is simple and can be modified as needed if your BAM does not conform to this format.</p>

         <div class= "panel panel-info">
            <div class= "panel-heading">
            <h3 class= "panel-title" data-toc-skip>Requirements</h3>
            </div>
            <div class= "panel-body">
<p>Requires <code>pysam</code> to be installed in your python environment.</p>
            </div>
          </div>

    <figure class="highlight">
    <pre><code class="language-bash" data-lang="bash">python get_insert_size_distribution_per_cell.py mybam.bam insert_sizes.txt --barcodes mybarcodes.txt</code></pre>
    </figure>

    <h3>Generating Banding Scores</h3>
    Using <code>insert_sizes.txt</code> as input, you can then generate banding scores.

    <figure class="highlight">
    <pre><code class="language-bash" data-lang="bash">Rscript calculate_nucleosome_banding_scores.R insert_sizes.txt banding_scores.txt --barcodes mybarcodes.txt</code></pre>
    </figure>

    The output file in this case is <code>banding_scores.txt</code>, a TSV separated file with <code>cell</code> and <code>nucleosome_score</code> as columns. Lower scores indicate less banding. We recommend plotting a distribution of all scores and setting a cutoff. In our case there was an long left tail that could be used to establish a pass-fail threshold for inclusion in downstream analysis.

    <div class="spacer"></div>

         <div class= "panel panel-info">
            <div class= "panel-heading">
            <h3 class= "panel-title" data-toc-skip>Requirements</h3>
            </div>
            <div class= "panel-body">
<p>Script requires <code>dplyr</code> and <code>argparse</code> to be installed in your R environment.</p>
            </div>
          </div>


    <h2>Monocle Support</h2>
         <div class= "panel panel-info">
            <div class= "panel-heading">
            <h3 class= "panel-title" data-toc-skip>Upcoming Integration</h3>
            </div>
            <div class= "panel-body">
<p>When we started this project no existing tools (to our knowledge) supported both sc-RNA-seq data and sc-ATAC-seq data. sc-ATAC-seq data requires different preprocessing strategies before input into dimensionality reduction and differential accessibility testing. However, as many functions, clustering and dimensionality reduction approaches as examples, should not really have to change, we didn't make an toolkit exclusive to sc-ATAC-seq data.</p>

<p>Our sc-RNA-seq toolkit, <a>Monocle</a>, should fully support sc-ATAC-seq data by the end of the summer and we expect that other popular tools will eventually support it as well.</p>

<p>Therefore, while we provide tutorial code below as examples of useful code that mirrors what we have used in our manuscript, we hope that some of it, as well as much additional functionality, will be enabled by existing tools soon.</p>
            </div>
          </div>



    <h2>Dimensionality Reduction</h2>
    While our dimensionality reduction approach (part of the LSI workflow we established) has been well documented here: <code>TODO</code>, there are a few details here that warrant some additional documentation.

    The input to all dimensionality reduction in the manuscript is the binarized count matrix that includes only qc filtered cells.

    TODO selecting peaks
    TODO make a quick function that encapsulates running TSNE.


    <h2>Clustering</h2>
    <p>In our manuscript, we performed clustering in tSNE space using an older version of Seurat (Louvain clustering). Seurat has since been updated in a way that breaks most of our original code. We also expect that many users might instead want to cluster in PCA space (although we expect the results to be broadly similar for this dataset).</p>

    <p>Below we show how to take PCA or tSNE coordinates generated via the approach described above as input to clustering with Seurat. Again, we imagine that this will become more streamlined once existing tools support ATAC-seq data, as algorithms that operate on a reduced dimension dataset, such as clustering, should work the same regardless of the original datatype.</p>

    <figure class="highlight">
    <pre><code class="language-r" data-lang="r">source('clustering/clustering.R')
# We provide a utility function to take the results from the dimensionality reduction
# performed above and put them in a Seurat object, although this code is simple
# and you may modify it to suit your needs
seurat_obj = make_seurat(binary_matrix, metadata=metadata, tsne_coords=reduce_dim_results$tsne_coords, svd_coords=reduce_dim_results$svd_coords)

# You may then use Seurat clustering approaches as normal with desired parameters (see Seurat tutorials)
seurat_obj = FindClusters(seurat_obj, reduction.type='pca', save.SNN=TRUE)
seurat_obj.tsne_clustering = FindClusters(seurat_obj, reduction.type='tsne', save.SNN=TRUE)
</code></pre>
    </figure>

    <h2>Cicero and Calculating Activity Scores</h2>
    <p><a href="https://cole-trapnell-lab.github.io/cicero-release/">Cicero</a>, a tool used in various parts of our analyses, has now been published (TODO link to publication). In addition to outputing maps of coaccessibility, it can also calculate gene activity scores as presented in our manuscript.</p>

    <p>For detailed documentation of Cicero and activity score calculations, we point you to the <a href="https://cole-trapnell-lab.github.io/cicero-release/">Cicero website</a>.</p>

    <h2>KNN-based scRNA-seq Integration</h2>
    <p>In our manuscript we make comparisons between gene level scores derived from our data (activity scores) and gene expression measurements from several sc-RNA-seq studies. As mentioned above, you may calculate activity scores using Cicero, or alternatively, this aproach can take other gene by cell matrices as input. For example, we have used aggregate read counts around TSSs or aggregate binarized counts in peaks, or even binarized counts in peaks overlapping promoters as inputs with reasonable success as well.</p>

    <p>We are in the process of wrapping up this functionality into an R package, but this is still in progress. For the time being, we provide the file <code>TODO</code> with the function <code>TODO</code> that carries out the approach used in our manuscript.</p>

    <figure class="highlight">
    <pre><code class="language-r" data-lang="r">source('knn/knn.R')
TODO</code></pre>
    </figure>


    <h2>LD Score Regression</h2>
    <p>LD Score Regression (LDSC) already has extensive documentation provided on <a href="https://github.com/bulik/ldsc">Github</a> and their <a href="https://github.com/bulik/ldsc/wiki">wiki</a>. In principle, all we are doing is taking a set of peaks for each cell type and then running LDSC on cell type individually, annotating which SNPs used by LDSC fall in the cell type's peaks. One model is generated per cell type in this fashion. In our case, we only annotate SNPs as falling in DA peaks should they lift over from the human genome to mouse, but this would be unncessary for human data.</p>

    <p>As LDSC has been widely used outside of our study, we expect others will likely develop their own tools for generating LDSC models, etc. However, here we provide some documentation of scripts that we used to run LDSC. We hope this provides a useful starting point if you are unsure how to apply LDSC to your data, although we do not currently plan to support these scripts as their own independent tools.</p>



</div>
</div>
</div>

<br>
<br>
<br>
<br>

{% include footer.html %}

</body>

</html>

